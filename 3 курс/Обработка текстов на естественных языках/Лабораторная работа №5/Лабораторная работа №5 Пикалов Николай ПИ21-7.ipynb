{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0425ac61-740a-44a5-ae6c-7a23d7f3cf17",
   "metadata": {},
   "source": [
    "# üßë‚Äçüî¨ –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ ‚Ññ5\n",
    "## üôã –ü–∏–∫–∞–ª–æ–≤ –ù–∏–∫–æ–ª–∞–π –ù–∏–∫–æ–ª–∞–µ–≤–∏—á\n",
    "## üìö –ü–ò21-7\n",
    "## üìÖ 06.12.2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb3aa87-431a-4202-94ae-00a9b22be0af",
   "metadata": {},
   "source": [
    "## üî∞ –ó–∞–¥–∞–Ω–∏–µ 1 –ò–∑—É—á–∏—Ç–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ attention –∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3ba3df-908f-4ebc-8c55-b9b35041d69b",
   "metadata": {},
   "source": [
    "## –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è Attention –∏ –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ ü§ñüìò\n",
    "\n",
    "### –¢–µ—Ö–Ω–æ–ª–æ–≥–∏—è Attention üëÄ\n",
    "\n",
    "- **–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ**: Attention ‚Äî —ç—Ç–æ –º–µ—Ö–∞–Ω–∏–∑–º –≤ –Ω–µ–π—Ä–æ—Å–µ—Ç—è—Ö, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –º–æ–¥–µ–ª–∏ —Å—Ñ–æ–∫—É—Å–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö —á–∞—Å—Ç—è—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ —É–ª—É—á—à–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ –∏ –ø–µ—Ä–µ–≤–æ–¥–∞.\n",
    "- **–§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª**: –ü–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ –æ–ø—Ä–µ–¥–µ–ª—è—Ç—å –≤–∞–∂–Ω–æ—Å—Ç—å —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —á–∞—Å—Ç–µ–π –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å–ª–æ–≤ –≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏, –¥–ª—è –±–æ–ª–µ–µ —Ç–æ—á–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞.\n",
    "- **–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ**: –û—Å–æ–±–µ–Ω–Ω–æ –ø–æ–ª–µ–∑–µ–Ω –≤ –∑–∞–¥–∞—á–∞—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞, —Ç–∞–∫–∏—Ö –∫–∞–∫ –º–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞, —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Ä–µ—á–∏)\n",
    "\n",
    "## –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ ‚öôÔ∏èüìö\n",
    "\n",
    "- **–û—Å–Ω–æ–≤–∞**: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã ‚Äî —ç—Ç–æ —Ç–∏–ø –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å–ª–æ—è—Ö –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö —Å–≤—è–∑–µ–π.\n",
    "- **–°–æ—Å—Ç–∞–≤**: –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –≤–∫–ª—é—á–∞–µ—Ç –≤ —Å–µ–±—è –±–ª–æ–∫–∏ –∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞ –∏ –¥–µ–∫–æ–¥–∏—Ä–æ–≤—â–∏–∫–∞. –ö–∞–∂–¥—ã–π –±–ª–æ–∫ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –ø–æ–¥—Å–ª–æ–µ–≤, —Ç–∞–∫–∏—Ö –∫–∞–∫:\n",
    "  - **–ú–Ω–æ–≥–æ—Å–ª–æ–π–Ω—ã–µ –ø–µ—Ä—Ü–µ–ø—Ç—Ä–æ–Ω—ã (MLP)**: –ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞.\n",
    "  - **–ú–µ—Ö–∞–Ω–∏–∑–º—ã —Å–∞–º–æ–≤–Ω–∏–º–∞–Ω–∏—è (Self-Attention)**: –ü–æ–∑–≤–æ–ª—è—é—Ç –∫–∞–∂–¥–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–æ–≤–∞—Ç—å —Å –¥—Ä—É–≥–∏–º–∏ —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.\n",
    "- **–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞**: –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç –≤—ã—Å–æ–∫—É—é —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏ —Ç–æ—á–Ω–æ—Å—Ç—å, –æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–∞–Ω–Ω—ã—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4601377-52c7-462e-a59c-d99dc1fbdccb",
   "metadata": {},
   "source": [
    "## üî∞ –ó–∞–¥–∞–Ω–∏–µ 2 \n",
    "### üó®Ô∏è –ü—Ä–∏–º–µ–Ω–∏—Ç–µ –æ–¥–∏–Ω –∏–∑ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤, –Ω–∞–ø—Ä–∏–º–µ—Ä BERT –∫ –∑–∞–¥–∞—á–µ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ—Ç–∑—ã–≤–æ–≤ –∫–ª–∏–µ–Ω—Ç–æ–≤.\n",
    "### üó®Ô∏è –°—Ä–∞–≤–Ω–∏—Ç–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ –º–µ—Ç–æ–¥–∞–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, —Å RNN.\n",
    "### üó®Ô∏è –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "674dfb01-26fc-4c15-9b82-f3cad56aa01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b709f8ca-a644-493b-a98a-d2f54d9a4f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "df = pd.read_csv('data/amazon_reviews.csv')\n",
    "df = df[['reviews.text', 'reviews.rating']]  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏\n",
    "df.dropna(inplace=True)  # –£–¥–∞–ª—è–µ–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa2e651-6ec0-43d6-8d75-9dc273254e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–π—Ç–∏–Ω–≥–∏ –≤ –±–∏–Ω–∞—Ä–Ω—ã–µ –º–µ—Ç–∫–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π –æ—Ç–∑—ã–≤ = 1, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π = 0)\n",
    "df['reviews.rating'] = df['reviews.rating'].apply(lambda x: 1 if x > 3 else 0)\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['reviews.text'], df['reviews.rating'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068575e-d9c5-4421-88c3-3c210bcd3768",
   "metadata": {},
   "source": [
    "## –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–π –º–µ—Ç–æ–¥ ML (TF-IDF + –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "804ffcb9-8bb9-464d-a5d9-9cc2ae020170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.40      0.55       579\n",
      "           1       0.94      0.99      0.96      5088\n",
      "\n",
      "    accuracy                           0.93      5667\n",
      "   macro avg       0.91      0.70      0.76      5667\n",
      "weighted avg       0.93      0.93      0.92      5667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–æ–≤\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "model_lr = LogisticRegression()\n",
    "model_lr.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "predictions_lr = model_lr.predict(X_test_tfidf)\n",
    "print(classification_report(y_test, predictions_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31c0e92-6c2c-434d-8aa9-916f30591895",
   "metadata": {},
   "source": [
    "## üìä –û—Ç—á—ë—Ç –ø–æ TF-IDF + –õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è\r\n",
    "\r\n",
    "- ‚úÖ **–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –æ—Ç–∑—ã–≤—ã (–∫–ª–∞—Å—Å 1):**\r\n",
    "  - –ú–æ–¥–µ–ª—å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç **–≤—ã—Å–æ–∫—É—é —Ç–æ—á–Ω–æ—Å—Ç—å –∏ –ø–æ–ª–Ω–æ—Ç—É** –¥–ª—è –∫–ª–∞—Å—Å–∞ 1, —á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤.\r\n",
    "\r\n",
    "- ‚ùå **–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ –æ—Ç–∑—ã–≤—ã (–∫–ª–∞—Å—Å 0):**\r\n",
    "  - –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –∫–ª–∞—Å—Å–∞ 0 –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ **–Ω–∏–∂–µ**, –ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞—è —Ç—Ä—É–¥–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ —Å –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–µ–π –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤.\r\n",
    "\r\n",
    "- üéØ **–û–±—â–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å:**\r\n",
    "  - –ú–æ–¥–µ–ª—å –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –æ–±—â–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –≤ **0.93**, —á—Ç–æ —è–≤–ª—è–µ—Ç—Å—è –¥–æ–≤–æ–ª—å–Ω–æ –≤—ã—Å–æ–∫–∏–º –ø–æ–∫–∞–∑–∞—Ç–µ–ª–µ–º.\r\n",
    "\r\n",
    "- üìâ **–°—Ä–µ–¥–Ω—è—è f1-–æ—Ü–µ–Ω–∫–∞ –ø–æ –º–∞–∫—Ä–æ:**\r\n",
    "  - –°—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ **0.76** –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ **—Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –∫–ª–∞—Å—Å–∞–º–∏**.\r\n",
    "\r\n",
    "- üîç **–í–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—Ä–µ–¥–Ω—è—è f1-–æ—Ü–µ–Ω–∫–∞:**\r\n",
    "  - –ó–Ω–∞—á–µ–Ω–∏–µ –≤ **0.92**, —É—á–∏—Ç—ã–≤–∞—é—â–µ–µ –ø–æ–¥–¥–µ—Ä–∂–∫—É, —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –ª—É—á—à—É—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –Ω–∞ –±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö –º–µ—Ç–∫–∞—Ö.\r\n",
    "\r\n",
    "## üìù –í—ã–≤–æ–¥—ã\r\n",
    "\r\n",
    "- üöÄ **–ú–æ–¥–µ–ª—å –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ —Å TF-IDF** –∫–∞–∂–µ—Ç—Å—è **—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π** –Ω–∞ –¥–∞–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è –ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤.\r\n",
    "- ‚öñÔ∏è **–î–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤** –∏–ª–∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º—ã –º–æ–≥—É—Ç —Å–Ω–∏–∂–∞—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö –æ—Ç–∑—ã–≤–æ–≤.\r\n",
    "–∫–∞—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fdabd7-c536-46c4-9042-9d99a481bf08",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ea455d-f93f-41a0-a8a3-847893939377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "max_len = 100 # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "max_words = 10000 # –†–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è\n",
    "\n",
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –ø–æ–¥–≥–æ–Ω–∫–∞ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train) # –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ X_train - —ç—Ç–æ —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–æ–≤ –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–Ω–¥–µ–∫—Å–æ–≤\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "\n",
    "# –ü–∞–¥–¥–∏–Ω–≥ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π\n",
    "X_train_pad = pad_sequences(sequences, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52afe212-27fe-4e65-a402-5fcdc7f3b1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ RNN\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 32)) # –°–ª–æ–π –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Å–ª–æ–≤\n",
    "model.add(SimpleRNN(32)) # RNN —Å–ª–æ–π —Å 32 —Å–∫—Ä—ã—Ç—ã–º–∏ —Å–æ—Å—Ç–æ—è–Ω–∏—è–º–∏\n",
    "model.add(Dense(1, activation='sigmoid')) # –í—ã—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π —Å —Å–∏–≥–º–æ–∏–¥–Ω–æ–π –∞–∫—Ç–∏–≤–∞—Ü–∏–µ–π –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "448b9688-f1db-48e3-80a4-eda5d9006b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ö–æ–º–ø–∏–ª—è—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aa6d84b-8589-4edb-8a46-c864675a4b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "142/142 [==============================] - 2s 10ms/step - loss: 0.0342 - acc: 0.9894 - val_loss: 0.1939 - val_acc: 0.9477\n",
      "Epoch 2/20\n",
      "142/142 [==============================] - 1s 9ms/step - loss: 0.0250 - acc: 0.9926 - val_loss: 0.2137 - val_acc: 0.9479\n",
      "Epoch 3/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0197 - acc: 0.9950 - val_loss: 0.2694 - val_acc: 0.9283\n",
      "Epoch 4/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0191 - acc: 0.9947 - val_loss: 0.2282 - val_acc: 0.9475\n",
      "Epoch 5/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0162 - acc: 0.9956 - val_loss: 0.2435 - val_acc: 0.9431\n",
      "Epoch 6/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0205 - acc: 0.9941 - val_loss: 0.2443 - val_acc: 0.9440\n",
      "Epoch 7/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0120 - acc: 0.9970 - val_loss: 0.2512 - val_acc: 0.9477\n",
      "Epoch 8/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0169 - acc: 0.9946 - val_loss: 0.2688 - val_acc: 0.9380\n",
      "Epoch 9/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0135 - acc: 0.9964 - val_loss: 0.2708 - val_acc: 0.9418\n",
      "Epoch 10/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0112 - acc: 0.9975 - val_loss: 0.3040 - val_acc: 0.9307\n",
      "Epoch 11/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0106 - acc: 0.9976 - val_loss: 0.4304 - val_acc: 0.9014\n",
      "Epoch 12/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0116 - acc: 0.9971 - val_loss: 0.2824 - val_acc: 0.9442\n",
      "Epoch 13/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0087 - acc: 0.9978 - val_loss: 0.2768 - val_acc: 0.9444\n",
      "Epoch 14/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0183 - acc: 0.9951 - val_loss: 0.2948 - val_acc: 0.9373\n",
      "Epoch 15/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0084 - acc: 0.9978 - val_loss: 0.2906 - val_acc: 0.9420\n",
      "Epoch 16/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0095 - acc: 0.9974 - val_loss: 0.3144 - val_acc: 0.9358\n",
      "Epoch 17/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0138 - acc: 0.9962 - val_loss: 0.3002 - val_acc: 0.9407\n",
      "Epoch 18/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0078 - acc: 0.9980 - val_loss: 0.3135 - val_acc: 0.9391\n",
      "Epoch 19/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0478 - acc: 0.9879 - val_loss: 0.3104 - val_acc: 0.9376\n",
      "Epoch 20/20\n",
      "142/142 [==============================] - 1s 10ms/step - loss: 0.0127 - acc: 0.9966 - val_loss: 0.3100 - val_acc: 0.9396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x18c03600ed0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏\n",
    "model.fit(X_train_pad, y_train, epochs=20, batch_size=128, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b11da-7aa6-42aa-98ef-cefa29639aff",
   "metadata": {},
   "source": [
    "## üìà –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è\r\n",
    "\r\n",
    "- üéØ **–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö (`acc`):**\r\n",
    "  - –£–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è —Å —Ç–µ—á–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏, –¥–æ—Å—Ç–∏–≥–∞—è –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–π —ç–ø–æ—Ö–µ **99.66%**.\r\n",
    "  - –≠—Ç–æ —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ, –Ω–∞ –∫–æ—Ç–æ—Ä—ã—Ö –æ–Ω–∞ –æ–±—É—á–∞–ª–∞—Å—å.\r\n",
    "\r\n",
    "- üìâ **–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –Ω–∞ –æ–±—É—á–∞—é—â–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö (`loss`):**\r\n",
    "  - –£–º–µ–Ω—å—à–∞–µ—Ç—Å—è, —á—Ç–æ —Å–≤–∏–¥–µ—Ç–µ–ª—å—Å—Ç–≤—É–µ—Ç –æ–± —É–ª—É—á—à–µ–Ω–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö.\r\n",
    "\r\n",
    "- üö´ **–¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö (`val_acc`):**\r\n",
    "  - –û—Å—Ç–∞–µ—Ç—Å—è –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å—Ç–∞–±–∏–ª—å–Ω–æ–π –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–π —ç–ø–æ—Ö–∏, –≤ —Å—Ä–µ–¥–Ω–µ–º –æ–∫–æ–ª–æ **94%**.\r\n",
    "  - –û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–±–∏–ª—å–Ω–æ–≥–æ —É–≤–µ–ª–∏—á–µ–Ω–∏—è –º–æ–∂–µ—Ç —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞ —Ç–æ, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–µ —É–ª—É—á—à–∞–µ—Ç —Å–≤–æ—é —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å –æ–±–æ–±—â–∞—Ç—å –¥–∞–Ω–Ω—ã–µ.\r\n",
    "\r\n",
    "- ‚ö†Ô∏è **–§—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö (`val_loss`):**\r\n",
    "  - –ù–∞—á–∏–Ω–∞–µ—Ç —É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å—Å—è –ø–æ—Å–ª–µ 10-–π —ç–ø–æ—Ö–∏, —á—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–æ–º **–ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è**.\r\n",
    "\r\n",
    "## üîç –í—ã–≤–æ–¥—ã –∏ —Å–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏\r\n",
    "\r\n",
    "- üõ†Ô∏è **–ü—Ä–æ—Ç–∏–≤–æ–¥–µ–π—Å—Ç–≤–∏–µ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—é:**\r\n",
    "  - –†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–µ—Ç–æ–¥–æ–≤ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏, —Ç–∞–∫–∏—Ö –∫–∞–∫ **Dropout**.\r\n",
    "  - –ü—Ä–∏–º–µ–Ω–∏—Ç—å **—Ä–∞–Ω–Ω—é—é –æ—Å—Ç–∞–Ω–æ–≤–∫—É** (Early Stopping) –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥–∞–ª—å–Ω–µ–π—à–µ–≥–æ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è.\r\n",
    "  - –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏.\r\n",
    "\r\n",
    "- üß™ **–≠–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—ã —Å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏:**\r\n",
    "  - –ò–∑–º–µ–Ω–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö –∏–ª–∏ —Ä–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞ (batch size), —á—Ç–æ–±—ã –Ω–∞–π—Ç–∏ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –±–∞–ª–∞–Ω—Å –º–µ–∂–¥—É —Ç–æ—á–Ω–æ—Å—Ç—å—é –∏ –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é.\r\n",
    "\r\n",
    "- üìä **–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:**\r\n",
    "  - –°—Ç—Ä–µ–º–∏—Ç—å—Å—è –∫ —É–ª—É—á—à–µ–Ω–∏—é –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–ª–∞ —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.\r\n",
    "—Ä–∞–±–æ—Ç–∞–ª–∞ —Å –Ω–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4258f072-b179-4080-ad36-b93ebe7b4993",
   "metadata": {},
   "source": [
    "## üî∞ –ó–∞–¥–∞–Ω–∏–µ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a8f6fe7-e4e4-4dab-9d5b-9afed1cf16d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é BERT\n",
    "def generate_text_with_bert(model, tokenizer, text, top_k=5):\n",
    "    # –ó–∞–º–µ–Ω—è–µ–º –æ–¥–Ω–æ –∏–∑ —Å–ª–æ–≤ –Ω–∞ [MASK]\n",
    "    masked_index = text.find(' ')\n",
    "    masked_text = text[:masked_index] + \" [MASK]\" + text[masked_index+1:]\n",
    "    \n",
    "    # –ö–æ–¥–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç\n",
    "    input_ids = tokenizer.encode(masked_text, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(input_ids == tokenizer.mask_token_id)[1]\n",
    "\n",
    "    # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Å–ª–æ–≤–æ\n",
    "    token_logits = model(input_ids).logits\n",
    "    mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "    \n",
    "    # –í—ã–±–∏—Ä–∞–µ–º top_k —Å–ª–æ–≤\n",
    "    top_k_tokens = torch.topk(mask_token_logits, top_k, dim=1).indices[0].tolist()\n",
    "    \n",
    "    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç—ã, –∑–∞–º–µ–Ω—è—è [MASK] –Ω–∞ –∫–∞–∂–¥–æ–µ –∏–∑ top_k —Å–ª–æ–≤\n",
    "    for token in top_k_tokens:\n",
    "        word = tokenizer.decode([token])\n",
    "        new_text = text[:masked_index] + \" \" + word + text[masked_index:]\n",
    "        print(f\"Generated text: {new_text}\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –¥–ª—è BERT (–¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞)\n",
    "tokenizer_en = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_en = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58373db5-eb3f-4b10-983f-9e948b76f328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: Hello, and my name is [MASK].\n",
      "Generated text: Hello, but my name is [MASK].\n",
      "Generated text: Hello, \" my name is [MASK].\n",
      "Generated text: Hello, hi my name is [MASK].\n",
      "Generated text: Hello, hello my name is [MASK].\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57a351264f6744cdabb872667a50f135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\divin\\PycharmProjects\\neuralnets2\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\divin\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f004569df7045dc9e748af3cb1bc117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ecfb082d4b48f5ae35527aed16a99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3ebb2278f744eca289025b3b89c27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307767316b8a46119c970bba94ed0f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/714M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text: –ü—Ä–∏–≤–µ—Ç, —á—Ç–æ –º–µ–Ω—è –∑–æ–≤—É—Ç [MASK].\n",
      "Generated text: –ü—Ä–∏–≤–µ—Ç, –∫–∞–∫ –º–µ–Ω—è –∑–æ–≤—É—Ç [MASK].\n",
      "Generated text: –ü—Ä–∏–≤–µ—Ç, —Ç–µ–ø–µ—Ä—å –º–µ–Ω—è –∑–æ–≤—É—Ç [MASK].\n",
      "Generated text: –ü—Ä–∏–≤–µ—Ç, –≤—Å–µ –º–µ–Ω—è –∑–æ–≤—É—Ç [MASK].\n",
      "Generated text: –ü—Ä–∏–≤–µ—Ç, –ø–æ—á–µ–º—É –º–µ–Ω—è –∑–æ–≤—É—Ç [MASK].\n"
     ]
    }
   ],
   "source": [
    "# –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º —è–∑—ã–∫–µ\n",
    "text_en = \"Hello, my name is [MASK].\"\n",
    "generate_text_with_bert(model_en, tokenizer_en, text_en)\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∞–π–∑–µ—Ä–∞ –¥–ª—è BERT (–¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞)\n",
    "tokenizer_ru = BertTokenizer.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "model_ru = BertForMaskedLM.from_pretrained('DeepPavlov/rubert-base-cased')\n",
    "\n",
    "# –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ\n",
    "text_ru = \"–ü—Ä–∏–≤–µ—Ç, –º–µ–Ω—è –∑–æ–≤—É—Ç [MASK].\"\n",
    "generate_text_with_bert(model_ru, tokenizer_ru, text_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d28f85-19a6-4257-ac9a-3631bdcc13e6",
   "metadata": {},
   "source": [
    "## –í—ã–≤–æ–¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34ff77c-1b13-49ed-aa81-158136febafa",
   "metadata": {},
   "source": [
    "## üî∞ –ó–∞–¥–∞–Ω–∏–µ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ec4893-1750-4966-8051-e54670fabbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
